---
title: "ML for Mechanical Modeling/Design: Vijayakumaran and Bessa 2024"
date: 2024-09-25T09:30:01+08:00
type : list-single
author: Xiwei Pan
slug: consistent-ml-to
draft: false
toc: true
categories:
  - reading
tags:
  - machine learning
  - topology optimization
  - multiscale structures
  - paper reading
---
## Preface to the series
This series ("ML for Mechanical Modeling/Design") consists of my notes on papers I read about *machine learning-assisted mechanical modeling or design*, primarily covering the overall logical structure of the articles, as well as their key points and contributions.

---

## Consistent machine learning for topology optimization with microstructure-dependent neural network material models

Here is the [article link <i class="fa fa-external-link" aria-hidden="true"></i>](https://arxiv.org/abs/2408.13843).

### New Contributions
> 1. Developed a framework for designing multiscale heterogeneous structures with spatially varying microstructures by <font color=Red>merging a homogenization-based topology optimization (TO) strategy with a consistent machine learning (ML) approach grounded in hyperelasticity theory</font>.
> 2. Leveraged neural architectures that <font color=Red>adhere to critical physical principles</font> such as polyconvexity, objectivity, material symmetry, and thermodynamic consistency to supply the framework with a reliable constitutive model that is dependent on material microstructural descriptors.

### Backgrounds
3D printing of various graded microstructures has been made possible by the advances in additive manufacturing, which has prompted a resurgence of homogenization-based methods in multiscale TO. Structures of unprecedented complexity have been both designed and physically realized at multiple scales[^1].

However, extending the existing single scale to two-scale concurrent design optimization methods for use with nonlinear physics is a particularly challenging task as <font color=Crimson>the relevant physics can no longer be approximated via linear, first-order homogenization theory.</font> Moreover, analytical homogenization methods are not available for arbitrarily complex microstructures, limiting what can be readily used in a homogenization based TO framework.

Data-driven homogenization techniques involving ML methods, specifically neural networks (NNs) and Gaussian processes for nonlinear material behavior, provide an elegant alternative to the expensive `$\mathrm{FE}^2$` method, and offer a means to account for the dependence of microstructural descriptors in the homogenized response. And NNs with recurrent units are even capable of modeling **history-dependent material responses**[^2]. <mark>Furthermore, a natural advantage of employing NNs to capture the homogenized constitutive behavior is the ease of obtaining derivatives for both the tangent stiffness of the material as well as the sensitivities in TO, leveraging automatic differentiation.</mark> The employment of ML in the context of TO for *elastic multiscale designs* can be found in these works[^3][^4].

What actually hinders the use of typical *black-box* NN constitutive models is <font color=Crimson>their failure to adhere to established physical principles, particularly in data-scarce situations</font>, leading to concerns about accuracy and numerical stability. In the case of **hyperelasticity**, this includes thermodynamic consistency, objectivity, existence of a natural state[^5], quasiconvexity, and volumetric growth conditions[^6], in addition to material dependent symmetry conditions.

> *Polyconvexity* is a convenient and tractable condition to ensure *quasiconvexity* (and thereby ellipticity), which is needed to prove the existence of minimizers for the variational problem being solved in the forward analysis. However, <font color=Chocolate>in the case of hyperelastic composites, the homogenization step can lead to a loss of ellipticity (and therefore, quasiconvexity) despite each phase individually being polyconvex.</font> This implies that even under a data-rich scenario, a *black-box* model trained using homogenized response data can exhibit microstructural instabilities leading to numerical difficulties in the forward analyses performed in the optimization loop. Thus, it becomes all the more important to wrap the homogenized response with a polyconvex envelope (sometimes refered to as polyconvexification) to ensure that the response is stable during the optimization procedure. The development of the input convex neural networks (ICNNs)[^7] has enabled significant progress in realizing NN-based models that attempt to incorporate polyconvexity among other relevant physical principles. In particular, Linden et al.[^8] have provided a rigorous framework for using ICNN based models in the context of hyperelasticity formulated in terms of strain invariants.


<font color=RoyalBlue>The present article addressed multiscale TO in geometrically and materially nonlinear settings by proposing a consistent machine learning-driven framework for hyperelastic composite structure design. This framework is composed of **the consistent ML block** that captures the homogenized constitutive response as a function of microstructural descriptors in an offline phase adhering to hyperelasticity principles, and **a multiscale TO block** that treats the microstructural descriptors as additional design variables in the nonlinear TO problem.</font> The illustration is shown below <i class="fa fa-level-down" aria-hidden="true"></i>
{{<figure src="/figures/blogFigs/ml_assisted/consistent_bessa1.png" caption="Figure 1: An overview of the proposed consistent machine learning-driven topology optimization framework for multiscale hyperelastic structures" width="800">}}

### Methodologies
The constitutive model employed in the multiscale TO framework presented here relies on a **first order computational homogenization** through finite element method (FEM) to compute the effective macroscopic response dataset corresponding to the microscopic representative volume element (RVE). We consider a total Lagrangian formulation and choose the Green-Lagrange strain tensor `$\pmb{E}$` as the primary kinematic variable, computed using the deformation gradient `$\pmb{F}$` and the right Cauchy-Green deformation tensor `$\pmb{C}$` via
`$$\pmb{C}:=\pmb{F}^\mathrm{T}\pmb{F};\quad \pmb{E}:=\frac{1}{2}\left(\pmb{C}-\pmb{1}\right)$$`


[^1]: Sanders, E.D., Pereira, A., Paulino, G.H., 2021. Optimal and continuous multilattice embedding. Science Advances 7.
[^2]: Mozaffar, M., Bostanabad, R., Chen, W., Ehmann, K., Cao, J., Bessa, M.A., 2019. Deep learning predicts path-dependent plasticity. Proceedings of the National Academy of Sciences 116, 26414–26420.
[^3]: White, D.A., Arrighi, W.J., Kudo, J., Watts, S.E., 2019. Multiscale topology optimization using neural network surrogate models. Computer Methods in Applied Mechanics and Engineering 346, 1118–1135.
[^4]: Chandrasekhar, A., Sridhara, S., Suresh, K., 2023. Graded multiscale topology optimization using neural networks. Advances in Engineering Software 175, 103359.
[^5]: Coleman, B.D., Noll, W., 1959. On the thermostatics of continuous media. Archive for Rational Mechanics and Analysis 4, 97–128.
[^6]: Ball, J.M., 1976. Convexity conditions and existence theorems in nonlinear elasticity. Archive for Rational Mechanics and Analysis 63, 337–403.
[^7]: Amos, B., Xu, L., Kolter, J.Z., 2017. Input convex neural networks, in: Precup, D., Teh, Y.W. (Eds.), Proceedings of the 34th International Conference on Machine Learning, PMLR. pp. 146–155.
[^8]: Linden, L., Klein, D.K., Kalina, K.A., Brummund, J., Weeger, O., Kästner, M., 2023. Neural networks meet hyperelasticity: A guide to enforcing physics. Journal of the Mechanics and Physics of Solids 179, 105363.