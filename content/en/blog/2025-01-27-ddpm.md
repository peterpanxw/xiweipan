---
title: "Image Diffusion by Pytorch"
date: 2025-01-27T10:34:05+08:00
type: list-single
author: Xiwei Pan
slug: image-diffusion
draft: false
toc: true
categories:
  - learning
tags:
  - diffusion models
  - machine learning
  - Python
---
## Preface
In [my previous blogs](https://xiweipan.com/tags/diffusion-models/), we have discussed the theoretical derivation of diffusion models, so Iâ€™d like to take this opportunity to walk through the code implementation of Denoising Diffusion Probabilistic Models (DDPM) and explore the logic behind building deep learning networks in PyTorch.

[The code](https://github.com/dome272/Diffusion-Models-pytorch) I use for investigating diffusion models was originally released by [dome272](https://github.com/dome272), so the associated code and data resources are easily accessible through the provided GitHub page. Here, I hope to take on two roles: first, by studying the specific diffusion model code, I aim to deepen my understanding of Python programming and the key PyTorch libraries; second, I want to integrate the conclusions related to DDPM network construction, which I have explored in my previous blogs, into a cohesive framework, allowing me and others to move more clearly into the practical implementation detail rather than getting lost in lengthy derivations.

## Algorithm and Related Formulations
According to *the second restriction* for an MHVAE to qualify as a VDM, the encoder structure must be pre-defined as a a Gaussian distribution centered around the output of the previous timestep, with the mean being `$\pmb{\mu}_t(\pmb{x}_t)=\sqrt{\alpha_t}\pmb{x}_{t-1}$` and the variance being `$\sum_t(\pmb{x}_t)=(1-\alpha_t)\pmb{\mathrm{I}}$`. Mathematically, this is given by
`$$q(\pmb{x}_t|\pmb{x}_{t-1})=\mathcal{N}(\pmb{x}_t; \sqrt{\alpha_t}\pmb{x}_{t-1},(1-\alpha_t)\pmb{\mathrm{I}}),\tag{1} \label{eq1}$$`
through [reparameterization trick](https://xiweipan.com/en/2024/07/10/diffusion-model-vae/#reparameterization-trick), samples at timestep `$t$` (`$\pmb{x}_t\sim q(\pmb{x}_t|\pmb{x}_{t-1})$`) can relate to a standard Gaussian `$\pmb{\epsilon}$`, that is
`$$\pmb{x}_t=\sqrt{\alpha_t}\pmb{x}_{t-1}+\sqrt{1-\alpha_t}\pmb{\epsilon},\quad\pmb{\epsilon}\sim\mathcal{N}(\pmb{\epsilon};\pmb{0},\pmb{\mathrm{I}}). \tag{2} \label{eq2}$$`

Note that the notation `$\beta_t=1-\alpha_t$`, commonly referred to as the 'diffusion coefficient', is also widely used in both papers and coding.

The diffused image `$q(\pmb{x}_t|\pmb{x}_0)$` can now be recursively derived using the reparameterization trick:
`$$\pmb{x}_t=\sqrt{\bar{\alpha}_t}\pmb{x}_0+\sqrt{1-\bar{\alpha}_t}\pmb{\epsilon}_0\sim\mathcal{N}\left(\pmb{x}_t;\sqrt{\bar{\alpha}_t}\pmb{x}_0,(1-\bar{\alpha}_t)\pmb{\mathrm{I}}\right), \tag{3} \label{eq3}$$`
here `$\bar{\alpha}_t=\prod_{i=1}^t\alpha_i$`. The image diffusion process is illustrated in Fig. 1, and the corresponding Python code is provided below.
{{<figure src="/figures/blogFigs/ddpmPython/car_noise.jpg" caption="Figure 1: Progressively diffuse an image using random noise." width="850">}}

```python
  import torch
  from torchvision.utils import make_grid, save_image
  from torchvision import transforms
  from PIL import Image

  beta = torch.linspace(0.02, 0.1, 1000).double()
  alpha = 1. - beta
  alpha_bar = torch.cumprod(alpha, dim=0)
  sqrt_alpha_bar = torch.sqrt(alpha_bar)
  sqrt_one_minus_alpha_bar = torch.sqrt(1 - alpha_bar)

  img = Image.open('car.jpg')  # read image
  trans = transforms.Compose([
      transforms.Resize(224),  # resize the input image to have a height and width of 224 pixels
      transforms.ToTensor()  # convert to tensor form
  ])
  x_0 = trans(img)
  img_list = [x_0]
  noise = torch.randn_like(x_0)  # standard Gaussian distribution
  for i in range(15):
      x_t = sqrt_alpha_bar[i] * x_0 + sqrt_one_minus_alpha_bar[i] * noise
      img_list.append(x_t)  # add items to the end of an image list

  all_img = torch.stack(img_list, dim=0)  # combine a list of tensors into a single tensor along a new dimension (dim=0 means the batch dimension)
  all_img = make_grid(all_img)  # default padding and nrow: 2*8
  save_image(all_img, 'car_noise.jpg')
```

